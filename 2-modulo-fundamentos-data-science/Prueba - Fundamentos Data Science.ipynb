{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'income-db.csv' does not exist: b'income-db.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a96e4caf9fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'income-db.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'income-db.csv' does not exist: b'income-db.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('income-db.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivo\n",
    "* Implementar los contenidos aprendidos a lo largo de las 8 unidades para resolver dos problemasde carácter obligatorio.\n",
    "* Se deben desarrollar dos desafíos aplicando lo aprendido en el módulo Fundamentos de DataScience.\n",
    "* Ambos desafíos presentarán un enunciado a solucionar, así como una descripción de los datosdisponibles a utilizar.\n",
    "* Cada una de las respuestas deben considerar los requerimientos mínimos y buenas prácticasdetalladas a continuación.\n",
    "\n",
    "### Consideraciones Generales\n",
    "La prueba debe desarrollarse en consideración a los siguientes puntos:\n",
    "* Una sección llamada Preliminares donde se realiza la descripción del problema y objetivos, asícomo explicar cómo implementarán su solución (debe considerar qué criterios de optimización ymétricas de desempeño).\n",
    "* Una sección llamada Aspectos computacionales donde se describirán las librerías y módulosa implementar, así como las funciones generadas y su objetivo.\n",
    "* Una sección llamada Descripción donde se generará un análisis descriptivo considerando eltipo de variables (desde el punto de vista estadístico así como computacional). Esta seccióndebe considerar medidas univariadas/ frecuencias, datos perdidos y gráficos distributivos sobrelas variables a analizar. A partir de ésta se debe clarificar la estrategia de preprocesamiento(datos perdidos, recodificaciones).\n",
    "* Una sección llamada Modelación descriptiva, que buscará definir cuáles son los principalesdeterminantes del objeto de estudio. En base a esta sección se podrá construír o depurar elmodelo predictivo.\n",
    "* Una sección llamada Modelación predictiva, donde se implementará una solución analítica queaumente las métricas de desempeño. Se solicitan por lo menos 3 modelos predictivos, dondedeberán reportar las principales métricas. Cada modelo predictivo debe tener una reseña sobreel por qué se diseño de esa forma.\n",
    "\n",
    "### Hito 1: Sesión Presencial 1, Unidad 7\n",
    "Completar el punto de Preliminares, así como Aspectos computacionales.\n",
    "* Elementos a considerar en éste hito:\n",
    "    * Los dos enunciados deben estar clarificados, considerando el tipo de problema a resolver(regresión o clasificación). Para cada uno de los enunciados y su problema identificado, sedebe justificar el uso de métricas para medir el desempeño del problema. (3 puntos)\n",
    "    * Se debe considerar el uso de las librerías asociadas para la ingesta, preprocesamiento,visualización y modelación, así como métricas de evaluación. (1 punto)\n",
    "    * Se debe detallar y considerar el proceso de preprocesamiento y recodificación de datos. (1punto)\n",
    "* Entregable: Dos notebooks (uno por enunciado) con todos los puntos detallados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 1: Determinantes del ingreso\n",
    "#### Enunciado\n",
    "Usted trabaja para un  organismo no  gubernamental que está interesado en  las  dinámicas socioeconómicas que determinan la desigualdad de ingreso y la erradicación de la pobreza extrema,enmarcado dentro de los objetivos del desarrollo del nuevo milenio del Programa de las NacionesUnidas para el  Desarrollo. Le  encomiendan el  desarrollo de  un  modelo predictivo  sobre la probabilidad que un individuo presente salarios por sobre o bajo los 50.000 dólares anuales, en basea una serie de atributos sociodemográficos.\n",
    "#### Aspectos adicionales a considerar\n",
    "* La base de datos contiene los valores perdidos como '?'. Deberá transformarlos para poder trabajar de forma adecuada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample()\n",
    "#las columnas 'native-country', 'workclass' y 'occupation' aparentemente son las unicas que tiene el '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df[df['occupation'] == '?' ].shape)\n",
    "print(df[df['workclass'] == '?' ].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('el porcentaje de los \"?\" en ocupation es de: ' ,round(((2809 /48842)*100), 2),'%')\n",
    "print('el porcentaje de los \"?\" en workclass es de: ' ,round(((2799 /48842)*100), 2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Desde la organización le sugieren que debe recodificar las siguientes variables acorde a las siguientes nomenclaturas:\n",
    "    * occupation debe recodificarse como collars siguiendo una nomenclatura similar a:\n",
    "        * white-collar $\\leftarrow$ Prof-specialty, Exec-managerial, Adm-clerical, Sales,Tech-support.\n",
    "        * blue-collar $\\leftarrow$ Craft-repair, Machine-op-inspct, Transport-moving,Handlers-cleaners, Farming-fishing, Protective-serv, Priv-house-serv.\n",
    "        * others $\\leftarrow$ Other-service, Armed-Forces.\n",
    "    * workclass debe recodificarse como workclass_recod siguiendo una nomenclatura similar a:\n",
    "        * federal-gov $\\leftarrow$ Federal-gov.\n",
    "        * state-level-gov $\\leftarrow$ State-gov, Local-gov.\n",
    "        * self-employed $\\leftarrow$ Self-emp-inc, Self-emp-not-inc\n",
    "        * unemployed $\\leftarrow$ Never-worked, Without-pay.\n",
    "    * education debe recodificarse como educ_recod siguiendo una nomenclatura similar a:\n",
    "        * preschool$\\leftarrow$ Preschool\n",
    "        * elementary-school$\\leftarrow$ 1st-4th, 5th-6th\n",
    "        * high-school$\\leftarrow$ 7th-8th, 9th, 10th,11th, 12th, HS-grad\n",
    "        * college$\\leftarrow$ Assoc-voc, Assoc-acdm, Some-college\n",
    "        * university$\\leftarrow$ Bachelors, Masters, Prof-school, Doctorate\n",
    "    * marital-status  debe recodificarse como civstatus  siguiendo una  nomenclaturasimilar a:\n",
    "        * married$\\leftarrow$ Married-civ-spouse, Married-spouse-absent, Married-AF-spouse\n",
    "        * divorced$\\leftarrow$ Divorced\n",
    "        * separated$\\leftarrow$ Separated\n",
    "        * widowed$\\leftarrow$ Widowed\n",
    "    * native-country debe recodificarse como region donde cada país debe asignarse a uno de los 5 continentes\n",
    "    * income debe recodificarse de forma binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desafio = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisar\n",
    "def asignador_valores(dataframe, colname, valor_original, valor_actualizado, directorio):\n",
    "    '''\n",
    "    lo que hace esta función es reemplazar los valores de la base de datos por '''\n",
    "    for indice, serie in dataframe.iterrows():\n",
    "        if serie[var] == media_pasajeros:\n",
    "            df['underperforming'].set_value(indice, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reemplazamos los valores usando el metodo replace\n",
    "#reemplazo de occupation\n",
    "df['occupation'] = df['occupation'].replace(['Prof-specialty', 'Exec-managerial', 'Adm-clerical','Sales','Tech-support',\n",
    "                                             #blue-collar\n",
    "                                             'Craft-repair','Machine-op-inspct','Transport-moving','Handlers-cleaners', \n",
    "                                             'Farming-fishing','Protective-serv','Priv-house-serv',\n",
    "                                            #others\n",
    "                                            'Other-service', 'Armed-Forces'],\n",
    "                                    ['white-collar','white-collar','white-collar','white-collar', 'white-collar',\n",
    "                                    'blue-collar', 'blue-collar', 'blue-collar','blue-collar', 'blue-collar', 'blue-collar'\n",
    "                                    , 'blue-collar','others', 'others'])\n",
    "#reemplazo de workclass\n",
    "df['workclass'] = df['workclass'].replace(['Federal-gov',\n",
    "                                         'State-gov', 'Local-gov',\n",
    "                                          'Self-emp-inc', 'Self-emp-not-inc',\n",
    "                                          'Never-worked', 'Without-pay'],\n",
    "                                        ['federal-gov','state-level-gov', 'state-level-gov',\n",
    "                                         'self-employed', 'self-employed', 'unemployed', 'unemployed'])\n",
    "#reemplazo education\n",
    "df['education'] = df['education'].replace(['Preschool',\n",
    "                                          '1st-4th', '5th-6th',\n",
    "                                          '7th-8th', '9th', '10th','11th', '12th', 'HS-grad',\n",
    "                                          'Assoc-voc', 'Assoc-acdm', 'Some-college',\n",
    "                                          'Bachelors', 'Masters', 'Prof-school', 'Doctorate'],\n",
    "                                         ['preschool', \n",
    "                                          'elementary-school', 'elementary-school',\n",
    "                                         'high-school', 'high-school', 'high-school','high-school', 'high-school', 'high-school',\n",
    "                                         'college', 'college', 'college',\n",
    "                                         'university', 'university', 'university', 'university'])\n",
    "#reemplazo marital-status\n",
    "df['marital-status'] = df['marital-status'].replace(['Married-civ-spouse', 'Married-spouse-absent', 'Married-AF-spouse',\n",
    "                                                    'Divorced',\n",
    "                                                    'Separated',\n",
    "                                                    'Widowed'],\n",
    "                                                   ['married','married', 'married',\n",
    "                                                   'divorced',\n",
    "                                                   'separated',\n",
    "                                                   'widowed'])\n",
    "#reemplazo native-country \n",
    "df['native-country'] = df['native-country'].replace (['United-States', 'Peru', 'Guatemala', 'Mexico','Dominican-Republic',\n",
    "                                                     'El-Salvador', 'Puerto-Rico', 'Columbia', 'Cuba', 'Canada',\n",
    "                                                     'Nicaragua', 'Honduras','Jamaica','Ecuador', 'Haiti','Trinadad&Tobago',\n",
    "                                                     'Outlying-US(Guam-USVI-etc)',\n",
    "                                                     #europa\n",
    "                                                      'Ireland', 'Germany','Poland', 'England', 'Italy', 'Portugal',\n",
    "                                                      'Scotland', 'Yugoslavia', 'Hungary', 'Greece', 'France',\n",
    "                                                      'Holand-Netherlands'\n",
    "                                                     #asia\n",
    "                                                      'Philippines', 'Thailand', 'Vietnam',\n",
    "                                                      'South', 'Japan', 'India', 'Cambodia', 'Laos', 'Taiwan', 'China',\n",
    "                                                      'Iran', 'Hong', 'Philippines'\n",
    "                                                      \n",
    "                                                     ],\n",
    "                                                     ['america', 'america','america', 'america', 'america',\n",
    "                                                     'america', 'america', 'america', 'america', 'america',\n",
    "                                                     'america','america','america','america', 'america', 'america',\n",
    "                                                      'america',\n",
    "                                                      #europa\n",
    "                                                     'europa', 'europa', 'europa', 'europa', 'europa', 'europa',\n",
    "                                                     'europa', 'europa', 'europa', 'europa', 'europa',\n",
    "                                                     'europa',\n",
    "                                                      #asia\n",
    "                                                      'asia', 'asia', 'asia',\n",
    "                                                      'asia', 'asia', 'asia', 'asia', 'asia', 'asia', 'asia',\n",
    "                                                      'asia', 'asia'\n",
    "                                                     ])\n",
    "#reemplazo de 'income' para dejar valores binarios\n",
    "df['income'] = np.where(df['income'] == '>50K', 1, 0)\n",
    "\n",
    "#recodificación de los nombre de las columnas\n",
    "df.columns = ['age', 'workclass_recode', 'fnlwgt', 'educ_recode', 'educational-num',\n",
    "       'civstatus', 'collars', 'relationship', 'race', 'gender',\n",
    "       'capital-gain', 'capital-loss', 'hours-per-week', 'region',\n",
    "       'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío 2: Rendimiento escolar\n",
    "#### Enunciado\n",
    "Lo contactan de una escuela Portuguesa para generar un modelo que identifique aquellos alumnos\n",
    "que presentan un bajo desempeño académico, medido en el promedio final del año escolar. Para ello\n",
    "le envían un archivo con registros sociodemográficos y conductuales de los alumnos dos escuelas\n",
    "para perfilar a los estudiantes.\n",
    "De manera adicional la psicopedagoga sugiere inspeccionar una batería de preguntas asociadas a\n",
    "aspectos ambientales del alumno (de famrel a health ) y ver si éstas se pueden abstraer en\n",
    "categorías latentes.\n",
    "### Aspectos adicionales a considerar\n",
    "* La base de datos presenta una serie de anomalías. En la escuela no tienen buenas prácticas sobre cómo ingresar datos, por lo que existen datos perdidos que están registrados bajo tres categorías: nulidade, sem validade, zero. De manera adicional, hay 3 variables numéricas que se registraron como strings, cuya interpretación en pandas devuelve una estructura de datos genérica. Finalmente, la base está con un encoding distinto al normal y los delimitadores son distintos.\n",
    "<br>\n",
    "* Para simplficar el análisis y su posterior inclusión en un modelo predictivo, se sugiere recodificar las variables binarias como 0 y 1. Se recomienda seguir en criterio de asignarle 1 a aquellas categorías minoritarias.\n",
    "<br>\n",
    "* El procedimiento también debe aplicarse para aquelas variables nominales con más de 2 categorías siguiendo la misma lógica.\n",
    "<br>\n",
    "* En la parte de modelación descriptiva, se deben generar modelos saturados por cada una de las notas registradas en G1 , G2 y G3.\n",
    "<br>\n",
    "* Para la parte de modelación predictiva, se debe generar un modelo para predecir las notas en G3 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student = pd.read_csv('students.csv')\n",
    "df_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
